{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d2c2f0",
   "metadata": {},
   "source": [
    "### Google Sheet Processing\n",
    "\n",
    "This script transforms the \"Clinical Benchmark and LLM\" Sheet into a sheet that is more friendly to process.\n",
    "\n",
    "This was used to create CoT-Difference-Sheet and CoT-Difference-Sheet-Invalid.\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79cec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def load_sheet(sheet_path):\n",
    "    '''\n",
    "    Input: path to excel sheet\n",
    "    Output: pandas dataframe of excel sheet\n",
    "    '''\n",
    "    sheet = pd.ExcelFile(sheet_path)\n",
    "\n",
    "    return sheet\n",
    "\n",
    "def define_columns():\n",
    "    '''\n",
    "    Function that defines all the columns to be used in final DataFrame\n",
    "\n",
    "    Input: None\n",
    "    Output: Dictionary mapping Column_Name --> Empty List\n",
    "    '''\n",
    "\n",
    "    columns = {\n",
    "        \"Model Name\": [],\n",
    "        \"Model Size\": [],\n",
    "        \"Model Domain\": [],\n",
    "        \"Task Name\": [],\n",
    "        \"Task Type\": [],\n",
    "        \"Direct Score\": [],\n",
    "        \"CoT Score\": [],\n",
    "        \"Direct Invalid Score\": [],\n",
    "        \"CoT Invalid Score\": [], \n",
    "        \"Difference\": [],\n",
    "        \"Relative Difference\": [],\n",
    "        \"Invalid Difference\": [],\n",
    "        \"Invalid Relative Difference\": []\n",
    "    }\n",
    "\n",
    "    return columns\n",
    "\n",
    "def define_models():\n",
    "    '''\n",
    "    Returns a list of all models used in the sheet\n",
    "    '''\n",
    "    models = [\n",
    "        \"Baichuan-M1-14B-Instruct\",\n",
    "        \"DeepSeek-R1\",\n",
    "        \"DeepSeek-R1-Distill-Llama-8B\",\n",
    "        \"DeepSeek-R1-Distill-Llama-70B\",\n",
    "        \"DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "        \"DeepSeek-R1-Distill-Qwen-7B\",\n",
    "        \"DeepSeek-R1-Distill-Qwen-14B\",\n",
    "        \"DeepSeek-R1-Distill-Qwen-32B\",\n",
    "        \"gemma-2-9b-it\",\n",
    "        \"gemma-2-27b-it\",\n",
    "        \"gemma-3-1b-it\",\n",
    "        \"gemma-3-4b-it\",\n",
    "        \"gemma-3-12b-it\",\n",
    "        \"gemma-3-27b-it\",\n",
    "        \"Llama-3.1-8B-Instruct\",\n",
    "        \"Llama-3.1-70B-Instruct\",\n",
    "        \"Llama-3.2-1B-Instruct\",\n",
    "        \"Llama-3.2-3B-Instruct\",\n",
    "        \"Llama-3.3-70B-Instruct\",\n",
    "        \"Llama-4-Scout-17B-16E-Instruct\",\n",
    "        \"Llama-3.1-Nemotron-70B-Instruct-HF\",\n",
    "        \"meditron-7b\",\n",
    "        \"meditron-70b\",\n",
    "        \"MeLLaMA-13B-chat\",\n",
    "        \"MeLLaMA-70B-chat\",\n",
    "        \"Llama3-OpenBioLLM-8B\",\n",
    "        \"Llama3-OpenBioLLM-70B\",\n",
    "        \"MMed-Llama-3-8B\",\n",
    "        \"Llama-3.1-8B-UltraMedical\",\n",
    "        \"Llama-3-70B-UltraMedical\",\n",
    "        \"Ministral-8B-Instruct-2410\",\n",
    "        \"Mistral-Small-Instruct-2409\",\n",
    "        \"Mistral-Small-24B-Instruct-2501\",\n",
    "        \"Mistral-Small-3.1-24B-Instruct-2503\",\n",
    "        \"Mistral-Large-Instruct-2411\",\n",
    "        \"BioMistral-7B\",\n",
    "        \"Phi-3.5-mini-instruct\",\n",
    "        \"Phi-3.5-MoE-instruct\",\n",
    "        \"Phi-4\",\n",
    "        \"Qwen2.5-1.5B-Instruct\",\n",
    "        \"Qwen2.5-3B-Instruct\",\n",
    "        \"Qwen2.5-7B-Instruct\",\n",
    "        \"Qwen2.5-72B-Instruct\",\n",
    "        \"QwQ-32B-Preview\",\n",
    "        \"QWQ-32B\",\n",
    "        \"Athene-V2-Chat\",\n",
    "        \"Yi-1.5-9B-Chat-16K\",\n",
    "        \"Yi-1.5-34B-Chat-16K\",\n",
    "        \"gpt-35-turbo-0125\",\n",
    "        \"gpt-4o-0806\",\n",
    "        \"gemini-2.0-flash-001\",\n",
    "        \"gemini-1.5-pro-002\"\n",
    "    ]\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "model_mapping = {\n",
    "    \"Baichuan-M1-14B-Instruct\": [14, \"med\"],\n",
    "    \"DeepSeek-R1\": [671, \"gen\"],\n",
    "    \"DeepSeek-R1-Distill-Llama-8B\": [8, \"gen\"],\n",
    "    \"DeepSeek-R1-Distill-Llama-70B\": [70, \"gen\"],\n",
    "    \"DeepSeek-R1-Distill-Qwen-1.5B\": [1.5, \"gen\"],\n",
    "    \"DeepSeek-R1-Distill-Qwen-7B\": [7, \"gen\"],\n",
    "    \"DeepSeek-R1-Distill-Qwen-14B\": [14, \"gen\"],\n",
    "    \"DeepSeek-R1-Distill-Qwen-32B\": [32, \"gen\"],\n",
    "    \"gemma-2-9b-it\": [9, \"gen\"],\n",
    "    \"gemma-2-27b-it\": [27, \"gen\"],\n",
    "    \"gemma-3-1b-it\": [1, \"gen\"],\n",
    "    \"gemma-3-4b-it\": [4, \"gen\"],\n",
    "    \"gemma-3-12b-it\": [12, \"gen\"],\n",
    "    \"gemma-3-27b-it\": [27, \"gen\"],\n",
    "    \"Llama-3.1-8B-Instruct\": [8, \"gen\"],\n",
    "    \"Llama-3.1-70B-Instruct\": [70, \"gen\"],\n",
    "    \"Llama-3.2-1B-Instruct\": [1, \"gen\"],\n",
    "    \"Llama-3.2-3B-Instruct\": [3, \"gen\"],\n",
    "    \"Llama-3.3-70B-Instruct\": [70, \"gen\"],\n",
    "    \"Llama-4-Scout-17B-16E-Instruct\": [109, \"gen\"],\n",
    "    \"Llama-3.1-Nemotron-70B-Instruct-HF\": [70, \"gen\"],\n",
    "    \"meditron-7b\": [7, \"med\"],\n",
    "    \"meditron-70b\": [70, \"med\"],\n",
    "    \"MeLLaMA-13B-chat\": [13, \"med\"],\n",
    "    \"MeLLaMA-70B-chat\": [70, \"med\"],\n",
    "    \"Llama3-OpenBioLLM-8B\": [8, \"med\"],\n",
    "    \"Llama3-OpenBioLLM-70B\": [70, \"med\"],\n",
    "    \"MMed-Llama-3-8B\": [8, \"med\"],\n",
    "    \"Llama-3.1-8B-UltraMedical\": [8, \"med\"],\n",
    "    \"Llama-3-70B-UltraMedical\": [70, \"med\"],\n",
    "    \"Ministral-8B-Instruct-2410\": [8, \"gen\"],\n",
    "    \"Mistral-Small-Instruct-2409\": [22, \"gen\"],\n",
    "    \"Mistral-Small-24B-Instruct-2501\": [24, \"gen\"],\n",
    "    \"Mistral-Small-3.1-24B-Instruct-2503\": [24, \"gen\"],\n",
    "    \"Mistral-Large-Instruct-2411\": [123, \"gen\"],\n",
    "    \"BioMistral-7B\": [7, \"med\"],\n",
    "    \"Phi-3.5-mini-instruct\": [4, \"gen\"],\n",
    "    \"Phi-3.5-MoE-instruct\": [42, \"gen\"],\n",
    "    \"Phi-4\": [14, \"gen\"],\n",
    "    \"Qwen2.5-1.5B-Instruct\": [1.5, \"gen\"],\n",
    "    \"Qwen2.5-3B-Instruct\": [3, \"gen\"],\n",
    "    \"Qwen2.5-7B-Instruct\": [7, \"gen\"],\n",
    "    \"Qwen2.5-72B-Instruct\": [72, \"gen\"],\n",
    "    \"QwQ-32B-Preview\": [32, \"gen\"],\n",
    "    \"QWQ-32B\": [32, \"gen\"],\n",
    "    \"Athene-V2-Chat\": [72, \"gen\"],\n",
    "    \"Yi-1.5-9B-Chat-16K\": [9, \"gen\"],\n",
    "    \"Yi-1.5-34B-Chat-16K\": [34, \"gen\"],\n",
    "    \"gpt-35-turbo-0125\": [None, \"gen\"],\n",
    "    \"gpt-4o-0806\": [None, \"gen\"],\n",
    "    \"gemini-2.0-flash-001\": [None, \"gen\"],\n",
    "    \"gemini-1.5-pro-002\": [None, \"gen\"],\n",
    "}\n",
    "\n",
    "def create_csv(data, output_path):\n",
    "    '''\n",
    "    Input: \n",
    "        - data: dictionary of information for the CSV\n",
    "        - output_path: string path to output csv\n",
    "\n",
    "    Output:\n",
    "        - None: saves CSV directly to your path\n",
    "\n",
    "    '''\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df.to_csv(output_path)\n",
    "    print(f\"CSV successfully created at {output_path}\")\n",
    "    return\n",
    "\n",
    "def filter_score(str_score):\n",
    "    '''\n",
    "    Input:\n",
    "        - str_score: string representation of score and range\n",
    "\n",
    "    Output:\n",
    "        - score: rounded float of score\n",
    "    '''\n",
    "\n",
    "    str_score = str_score.split(\" \")[0]\n",
    "    score = float(str_score)\n",
    "\n",
    "    return score\n",
    "\n",
    "columns = define_columns()\n",
    "\n",
    "all_models = define_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dce7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sheet(google_sheet, sheet_names, all_models, task_type):\n",
    "    '''\n",
    "    Inputs:\n",
    "        - google_sheet: pandas dataframe of the google sheet\n",
    "        - sheet_name: names of the specific sheet to process in the format [Direct Sheet, CoT Sheet]\n",
    "\n",
    "    Outputs:\n",
    "        - processed_sheet: pandas dataframe that can be turned into CSV\n",
    "    '''\n",
    "\n",
    "    # Define columns to output all data in\n",
    "    columns = define_columns()\n",
    "\n",
    "    # Number of models = length of number of tasks\n",
    "    direct_sheet_data = google_sheet.parse(sheet_names[0])\n",
    "    cot_sheet_data = google_sheet.parse(sheet_names[1])\n",
    "\n",
    "    # Iterate through each model column\n",
    "    for model in all_models:\n",
    "        \n",
    "        if task_type == \"clf\":\n",
    "            model_name = model\n",
    "            invalid_name = model + \".3\"\n",
    "\n",
    "        elif task_type == 'ext':\n",
    "            model_name = model + \".1\"\n",
    "            invalid_name = model + \".2\"\n",
    "\n",
    "        elif task_type == 'gen':\n",
    "            model_name = model + \".1\"\n",
    "            invalid_name = model + \".3\"\n",
    "\n",
    "        else:\n",
    "            raise KeyError(\"Task type not recognized\")\n",
    "\n",
    "        # For each model, iterate through each row in sheet\n",
    "        for row_idx, score in enumerate(direct_sheet_data[model_name]):\n",
    "            cot_score = cot_sheet_data[model_name][row_idx]\n",
    "            tt = direct_sheet_data['Task Type'][row_idx]\n",
    "\n",
    "            direct_invalid_score = direct_sheet_data[invalid_name][row_idx]\n",
    "            cot_invalid_score = cot_sheet_data[invalid_name][row_idx]\n",
    "\n",
    "\n",
    "            # Logic for first row\n",
    "            if row_idx == 0:\n",
    "                continue\n",
    "\n",
    "            # Logic for last row\n",
    "            if tt == '-':\n",
    "                break\n",
    "\n",
    "            direct_score = filter_score(score)\n",
    "            cot_score = filter_score(cot_score)\n",
    "\n",
    "            direct_invalid_score = filter_score(direct_invalid_score)\n",
    "            cot_invalid_score = filter_score(cot_invalid_score)\n",
    "\n",
    "            invalid_difference = round(cot_invalid_score - direct_invalid_score, 2)\n",
    "\n",
    "            if direct_invalid_score == 0:\n",
    "                invalid_relative_difference = 'N/A'\n",
    "            else:\n",
    "                invalid_relative_difference = round(invalid_difference / direct_invalid_score, 2)\n",
    "            \n",
    "\n",
    "            columns[\"Model Name\"].append(model)\n",
    "            columns[\"Model Size\"].append(model_mapping[model][0])\n",
    "            columns[\"Model Domain\"].append(model_mapping[model][1])\n",
    "            columns[\"Task Name\"].append(direct_sheet_data['Task name'][row_idx])\n",
    "            columns[\"Task Type\"].append(direct_sheet_data['Task Type'][row_idx])\n",
    "            columns[\"Direct Score\"].append(direct_score)\n",
    "            columns[\"CoT Score\"].append(cot_score)\n",
    "            columns[\"Direct Invalid Score\"].append(direct_invalid_score)\n",
    "            columns[\"CoT Invalid Score\"].append(cot_invalid_score)\n",
    "            columns[\"Difference\"].append(round(direct_score - cot_score, 2))\n",
    "            columns[\"Invalid Difference\"].append(invalid_difference)\n",
    "            columns[\"Invalid Relative Difference\"].append(invalid_relative_difference)\n",
    "\n",
    "            if direct_score == 0:\n",
    "                relative_diff = 0\n",
    "            else:\n",
    "                relative_diff = (direct_score - cot_score) / direct_score\n",
    "            columns[\"Relative Difference\"].append(round(relative_diff, 2))\n",
    "\n",
    "    return columns\n",
    "\n",
    "\n",
    "sheet_path = \"/Users/kevinxie/Desktop/LLM CoT/LLM-CoT/Reference for Clinical Benchmark and LLM.xlsx\"\n",
    "\n",
    "google_sheet = load_sheet(sheet_path)\n",
    "\n",
    "clf_data = process_sheet(google_sheet, ['B-CLF', 'B-CLF-CoT'], all_models, 'clf')\n",
    "\n",
    "ext_data = process_sheet(google_sheet, ['B-EXT', 'B-EXT-CoT'], all_models, 'ext')\n",
    "\n",
    "gen_data = process_sheet(google_sheet, ['B-GEN', 'B-GEN-CoT'], all_models, 'gen')\n",
    "\n",
    "\n",
    "# Directly add the calculations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b088e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV successfully created at CLF-Difference-Sheet-Invalid.csv\n",
      "CSV successfully created at EXT-Difference-Sheet-Invalid.csv\n",
      "CSV successfully created at Gen-Difference-Sheet-Invalid.csv\n"
     ]
    }
   ],
   "source": [
    "create_csv(clf_data, \"CLF-Difference-Sheet-Invalid.csv\")\n",
    "\n",
    "create_csv(ext_data, \"EXT-Difference-Sheet-Invalid.csv\")\n",
    "\n",
    "create_csv(gen_data, \"Gen-Difference-Sheet-Invalid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb54025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
