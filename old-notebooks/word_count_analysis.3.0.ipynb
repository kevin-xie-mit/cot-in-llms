{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52ce9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "import os\n",
    "import json\n",
    "# from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Path to base folder in Drive\n",
    "base_dir = '/content/drive/MyDrive/cot-analysis/cot_length'\n",
    "\n",
    "def count_word_multilingual(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Performs rough tokenization of the input text and counts the number of tokens.\n",
    "    Supports mixed languages including English, Chinese (including Japanese Kanji), \n",
    "    Spanish, Portuguese, French, German, Russian, Norwegian, and Japanese.\n",
    "    \n",
    "    Rules:\n",
    "    1) [0-9\\\\.]+ : Matches consecutive digits (including decimal points) as a single token.\n",
    "    2) \\\\p{Han} : Matches a single Chinese character (including Kanji used in Japanese).\n",
    "    3) \\\\p{Hiragana}+ : Matches consecutive Hiragana characters as a single token.\n",
    "    4) \\\\p{Katakana}+ : Matches consecutive Katakana characters as a single token.\n",
    "    5) \\\\p{Cyrillic}+ : Matches consecutive Cyrillic letters (Russian).\n",
    "    6) \\\\p{Latin}+ : Matches consecutive Latin letters (including diacritics),\n",
    "                     supporting English, Spanish, Portuguese, French, German, Norwegian, etc.\n",
    "    \n",
    "    Notes:\n",
    "    - Each Chinese character (\\\\p{Han}) is treated as an individual token. \n",
    "      For example, \"你好\" => [\"你\", \"好\"].\n",
    "    - Consecutive characters from other scripts (e.g., \"hello\") are treated as a single token.\n",
    "    - This is a simplified example and does not handle other symbols, punctuation, \n",
    "      or complex numerical formats.\n",
    "    - Requires the third-party module `regex` (pip install regex),\n",
    "      because the built-in `re` module has incomplete support for Unicode properties \\\\p{...}.\n",
    "    \"\"\"\n",
    "    pattern = (\n",
    "        r'[0-9\\.]+'        # Consecutive digits and decimal points\n",
    "        r'|\\p{Han}'        # Single Chinese character\n",
    "        r'|\\p{Hiragana}+'  # Consecutive Hiragana characters\n",
    "        r'|\\p{Katakana}+'  # Consecutive Katakana characters\n",
    "        r'|\\p{Cyrillic}+'  # Consecutive Cyrillic letters\n",
    "        r'|\\p{Latin}+'     # Consecutive Latin letters (including diacritics)\n",
    "    )\n",
    "    tokens = regex.findall(pattern, text)\n",
    "    return tokens, len(tokens)\n",
    "\n",
    "\n",
    "def sort_files(files_list):\n",
    "\n",
    "    num_re = re.compile(r\"^(\\d+)\")  # capture 1+ digits at start\n",
    "\n",
    "    def leading_num(fname):\n",
    "        m = num_re.match(fname)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "        else:\n",
    "            return float(\"inf\")  # or 0, depending on where you want no‑number files\n",
    "\n",
    "    sorted_files = sorted(files_list, key=leading_num)\n",
    "    \n",
    "    return sorted_files\n",
    "\n",
    "def split_by_analysis(\n",
    "    instructions: str,\n",
    "    prediction: str,\n",
    "    record_id: Any\n",
    ") -> Tuple[str, Optional[str], Any]:\n",
    "    \"\"\"\n",
    "    Split a model’s output into (analysis, result) based on markers.\n",
    "\n",
    "    Tries, in order:\n",
    "    1. Splitting on the literal \"Result:\" in the prediction.\n",
    "    2. Deriving the result label from instructions (e.g. \"Result: XYZ:\"),\n",
    "       then splitting on \"XYZ:\" in the prediction.\n",
    "    Falls back to returning the whole prediction as analysis with result=None.\n",
    "    \"\"\"\n",
    "    # Should first split by <think>\n",
    "\n",
    "    # 1) Try literal \"Result:\" in prediction\n",
    "    try:\n",
    "        analysis, result = prediction.split(\"Result:\", 1)\n",
    "        return analysis.strip(), result.strip(), record_id\n",
    "    except ValueError:\n",
    "        pass  # no \"Result:\" marker in prediction\n",
    "\n",
    "    # 2) Derive the label from instructions, e.g. instructions contains \"Result: XYZ:\"\n",
    "    match = re.search(r\"Result:\\s*([^:\\s]+):\", instructions)\n",
    "\n",
    "    if match:\n",
    "        label = match.group(1)\n",
    "        marker = f\"{label}:\"\n",
    "        try:\n",
    "            analysis, result = prediction.split(marker, 1)\n",
    "            return analysis.strip(), result.strip(), record_id\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # 3) Fallback\n",
    "    return prediction.strip(), None, record_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT FORMAT\n",
    "d = {\n",
    "    \"Task Name\": '',\n",
    "    \"Model Name\": '',\n",
    "    \"Number of Tokens\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4c8355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse :\n",
      "\n",
      "Le texte décrit le cas d'une patiente, Mlle L..., âgée de 25 ans, qui a été hospitalisée pour malaise et hématurie avec caillots en septembre 2001. Les examens biologiques ont révélé une anémie importante et une fonction rénale normale. Les traitements ont inclus des irrigations, des cystoscopies, des biopsies et des traitements antiviraux. La patiente a eu plusieurs épisodes de récidive, mais a finalement été guérie après un traitement prolongé.\n",
      "\n",
      "Résultat :\n",
      "\n",
      "age : 20\n",
      "genre : féminin\n",
      "issue : guérison\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Analyse',\n",
       "  'Le',\n",
       "  'texte',\n",
       "  'décrit',\n",
       "  'le',\n",
       "  'cas',\n",
       "  'd',\n",
       "  'une',\n",
       "  'patiente',\n",
       "  'Mlle',\n",
       "  'L',\n",
       "  '...',\n",
       "  'âgée',\n",
       "  'de',\n",
       "  '25',\n",
       "  'ans',\n",
       "  'qui',\n",
       "  'a',\n",
       "  'été',\n",
       "  'hospitalisée',\n",
       "  'pour',\n",
       "  'malaise',\n",
       "  'et',\n",
       "  'hématurie',\n",
       "  'avec',\n",
       "  'caillots',\n",
       "  'en',\n",
       "  'septembre',\n",
       "  '2001.',\n",
       "  'Les',\n",
       "  'examens',\n",
       "  'biologiques',\n",
       "  'ont',\n",
       "  'révélé',\n",
       "  'une',\n",
       "  'anémie',\n",
       "  'importante',\n",
       "  'et',\n",
       "  'une',\n",
       "  'fonction',\n",
       "  'rénale',\n",
       "  'normale',\n",
       "  '.',\n",
       "  'Les',\n",
       "  'traitements',\n",
       "  'ont',\n",
       "  'inclus',\n",
       "  'des',\n",
       "  'irrigations',\n",
       "  'des',\n",
       "  'cystoscopies',\n",
       "  'des',\n",
       "  'biopsies',\n",
       "  'et',\n",
       "  'des',\n",
       "  'traitements',\n",
       "  'antiviraux',\n",
       "  '.',\n",
       "  'La',\n",
       "  'patiente',\n",
       "  'a',\n",
       "  'eu',\n",
       "  'plusieurs',\n",
       "  'épisodes',\n",
       "  'de',\n",
       "  'récidive',\n",
       "  'mais',\n",
       "  'a',\n",
       "  'finalement',\n",
       "  'été',\n",
       "  'guérie',\n",
       "  'après',\n",
       "  'un',\n",
       "  'traitement',\n",
       "  'prolongé',\n",
       "  '.',\n",
       "  'Résultat',\n",
       "  'age',\n",
       "  '20',\n",
       "  'genre',\n",
       "  'féminin',\n",
       "  'issue',\n",
       "  'guérison'],\n",
       " 83)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "        \"task\": \"91-1.CAS.label\",\n",
    "        \"language\": \"fr\",\n",
    "        \"type\": \"ext\",\n",
    "        \"id\": 702,\n",
    "        \"split\": \"test\",\n",
    "        \"instruction\": \"Given the clinical care report in French, extract the following medical information:\\n- \\\"age\\\":  l'âge de la personne dont le cas est décrit, au moment du dernier élément clinique rapporté dans le cas clinique, normalisé sous la forme d'un entier (soit 0 pour un nourrisson de moins d'un an, 1 pour un enfant de moins de deux ans, y compris un an et demi, 20 pour un patient d'une vingtaine d'années, etc.).\\n- \\\"genre\\\": le genre de la personne dont le cas est décrit, parmi deux valeurs normalisées : féminin, masculin (il n'existe aucun cas de dysgénésie ou d'hermaphrodisme dans le corpus). si le genre n'est pas mentionné, retournez \\\"None\\\".\\n- \\\"issue\\\": l'issue parmi cinq valeurs possibles: (1) guérison (le problème clinique décrit dans le cas a été traité et la personne est guérie), (2) amélioration (l'état clinique est amélioré sans qu'on ne puisse conclure à une guérison), (3) stable (soit l'état clinique reste stationnaire, soit il est impossible de déterminer entre amélioration et détérioration), (4) détérioration (l'état clinique se dégrade), ou (5) décès (lorsque le décès concerne directement le cas clinique décrit). si le problème n'est pas mentionné, retournez \\\"None\\\".\\nSolve it in a step-by-step fashion, return your answer in the following format, PROVIDE DETAILED ANALYSIS BEFORE THE RESULT:\\nAnalysis:\\n...\\nResult:\\nage: ..., genre: ..., issue: ...\\nThe optional list for \\\"genre\\\" is [\\\"féminin\\\", \\\"masculin\\\", \\\"None\\\"].\\nThe optional list for \\\"issue\\\" is [\\\"guérison\\\", \\\"amélioration\\\", \\\"stable\\\", \\\"détérioration\\\", \\\"décès\\\", \\\"None\\\"].\",\n",
    "        \"input\": \"Mlle L… 25 ans a été adressée aux urgences du CHU de Bordeaux pour malaise le 26 septembre 2001. Elle présentait une hématurie avec caillots, évoluant depuis une semaine ainsi que des signes cliniques d’anémie.\\n\\nLes examens biologiques mettaient en évidence une anémie importante avec une hémoglobinémie à 5 grammes/100 ml sans autres anomalies à l’hémogramme, la fonction rénale était normale.\\n\\nHospitalisée en hématologie, une échographie ne mettait pas en évidence d’anomalies sur le haut appareil urinaire et trouvait dans la vessie des formations hyperéchogènes évoquant des caillots. Un sondage avec une sonde rigide confirmait la présence de caillots. Des manœuvres de décaillotage ont été entreprises au lit de la malade et une irrigation de sérum physiologique a été mise en place.\\n\\nLe 27 septembre 2001 a été réalisée au bloc opératoire une cystoscopie. Après décaillotage on constatait une muqueuse vésicale inflammatoire avec suffusions hémorragiques diffuses de toute la paroi vésicale sans lésion hémorragique particulière. Une nouvelle irrigation a été mise en place et un traitement hémostatique par acide tranexamique (EXACYL®) a été entrepris.\\n\\nLe 2 octobre 2001, un scanner abdomino-pelvien avec injection retrouvait un épaississement irrégulier de la paroi vésicale avec un contenu hétérogène de la vessie sans anomalies par ailleurs. Le haut appareil était normal et non dilaté. Le 3 octobre 2001 une nouvelle cystoscopie avec un décaillotage et des biopsies de la paroi vésicale a été réalisée. Une irrigation continue avec des sels d’aluminium a été commencée. Les urines sont devenues claires au troisième jour. L’examen anatomopathologique mettait en évidence une hyperplasie urothéliale avec discrètes atypies de nature indéterminée sans foyer tumoral visible. Les examens bactériologiques urinaires ont été négatifs. L’évolution étant satisfaisante, la sortie de la patiente a été décidée.\\n\\nLe 19 octobre 2001, Mme L... a été de nouveau hospitalisée pour hématurie avec caillots, les examens biologiques retrouvaient une anémie avec une hémoglobinémie à 5,4 g/100 ml. Le bilan étiologique par des analyses virologiques (recherche de cytomégalovirus, BK virus et JC virus dans le sang et les urines) et une cytologie urinaire ont été réalisés.\\n\\nUne nouvelle irrigation par sels d’aluminium a été débutée et continuée pendant 8 jours. Deux jours plus tard on a constaté un caillotage de la vessie et l’hémoglobine à 5,9 g/100 ml malgré les transfusions. On a réalisé une cystoscopie et 2 sondes urétérales ont été mises en place.\\n\\nLe bilan biologique retrouvait une PCR positive à JC virus dans le sang et à BK virus dans les urines. La cytologie urinaire ne retrouvait pas de signes d’infestation cellulaire par un agent viral. Le 30/10/01 a été entrepris un traitement antiviral par cidofoviristide®. Les sondes urétérales et vésicales ont été enlevées le 04/11/01, l’irrigation par sels d’aluminium a été arrêtée. Le 07/11/01 l’hématurie a été de nouveau importante avec caillots et déglobulisation et une hémoglobulinémie a 6,5g/100 ml.\\n\\nOn a réalisé de nouveau une cystoscopie et des sondes urétérales ont été mises en place. Le traitement antiviral a été continué. Un traitement par instillation endovésicale de prostaglandines a été débuté et poursuivi pendant 7 jours. La sonde vésicale a été enlevée ; il existait encore un caillotage vésical. Une semaine plus tard après une cystoscopie et un nouveau décaillotage, les urines sont restées claires et les sondes urétérales et vésicales ont été enlevées 3 jours plus tard. L’hémoglobine était stable a 8,8g/100 ml. Au total 24 culots globulaires auront été transfusés. La patiente a été autorisée à sortir le 21/11/01.\\n\\nRevue à la consultation 3 semaines plus tard, l’hématurie s’était arrêtée, l’hémoglobine était à 8,5g/100 ml. Les prélèvements viraux de contrôle ne retrouvaient pas de virus. Trois mois plus tard un nouveau contrôle urinaire ne retrouvait pas de trace du virus, l’hémoglobine était à 10,5 g/100 ml. La patiente se plaignait d’une pollakiurie, un examen urodynamique retrouvait une vessie hypocompliante avec une augmentation des pressions probablement secondaire aux traitements endovésicaux.\",\n",
    "        \"output\": \"age: 25, genre: féminin, issue: stable\",\n",
    "        \"pred\": \"Analyse :\\n\\nLe texte décrit le cas d'une patiente, Mlle L..., âgée de 25 ans, qui a été hospitalisée pour malaise et hématurie avec caillots en septembre 2001. Les examens biologiques ont révélé une anémie importante et une fonction rénale normale. Les traitements ont inclus des irrigations, des cystoscopies, des biopsies et des traitements antiviraux. La patiente a eu plusieurs épisodes de récidive, mais a finalement été guérie après un traitement prolongé.\\n\\nRésultat :\\n\\nage : 20\\ngenre : féminin\\nissue : guérison\",\n",
    "        \"CoT Length\": 83\n",
    "    }\n",
    "\n",
    "\n",
    "pred, _, _ = split_by_analysis(\n",
    "    d['instruction'],\n",
    "    d['pred'],\n",
    "    d['id']\n",
    ")\n",
    "\n",
    "print(pred)\n",
    "count_word_multilingual(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = pd.ExcelFile(\"/Users/kevinxie/Desktop/LLM CoT/LLM-CoT/Clinical Benchmark and LLM.xlsx\")\n",
    "data = sheet.parse(\"Task-all\")\n",
    "\n",
    "destination = \"/Users/kevinxie/Library/CloudStorage/GoogleDrive-kevinxie2024@gmail.com/My Drive/cot-analysis/combined-results\"\n",
    "\n",
    "task_folders = os.listdir(destination)\n",
    "\n",
    "valid_tasks = []\n",
    "for task_name in data['Task-Original']:\n",
    "    valid_tasks.append(task_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202f846",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "- There is an output file (.json) for each model-task pair. \n",
    "- We create 10 folders, each representing the 10% increments in length\n",
    "- For each output file, we get the lengths of EACH individual output\n",
    "- Then sort them\n",
    "- Bucket and add to each of the 10 folders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43549d1",
   "metadata": {},
   "source": [
    "## Simplified Task Name Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac126669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task name to simplified task name mapping\n",
    "google_sheet = pd.ExcelFile(\"Clinical Benchmark and LLM.xlsx\")\n",
    "\n",
    "data = google_sheet.parse(\"Task-all\")\n",
    "\n",
    "task_name_mapping = {}\n",
    "\n",
    "for row_idx, task_name in enumerate(data[\"Task-Original\"]):\n",
    "    task_name_mapping[data[\"Task name\"][row_idx]] = data[\"Task name\"][row_idx]\n",
    "    task_name_mapping[task_name] = data[\"Task name\"][row_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_cot_length(json_path):\n",
    "    \"\"\"\n",
    "    Given a json file of data, return the number of tokens in the analysis and result\n",
    "    and add to each entry.\n",
    "\n",
    "    RETURNS:\n",
    "        - Augments the json file with the length of CoT analysis\n",
    "        - returns the same list of dictionaries\n",
    "    \"\"\"\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_content = json.load(f)\n",
    "    \n",
    "    for d in json_content:\n",
    "        analysis, _, _ = split_by_analysis(d[\"instruction\"], d[\"pred\"], d[\"id\"])\n",
    "        _, num_tokens = count_word_multilingual(analysis)\n",
    "\n",
    "        d['CoT Length'] = num_tokens\n",
    "\n",
    "    return json_content\n",
    "\n",
    "def bucket(json_content):\n",
    "    \"\"\"\n",
    "    Given a json file of data with each output's CoT length,\n",
    "    bucket them into 10 different buckets (0-10, 10-20, ..., 90-100)\n",
    "    and return as 10 different files\n",
    "\n",
    "    RETURNS:\n",
    "        - returns a list of 10 lists, each containing the data for that bucket, in decreasing order\n",
    "    \"\"\"\n",
    "    # Step 1: Sort the data in descending order of \"CoT Length\"\n",
    "    sorted_data = sorted(json_content, key=lambda x: x['CoT Length'], reverse=True)\n",
    "\n",
    "    # Step 2: Split into 10 buckets (deciles)\n",
    "    total_items = len(sorted_data)\n",
    "    bucket_size = math.ceil(total_items / 10)\n",
    "\n",
    "    decile_buckets = [\n",
    "        sorted_data[i * bucket_size: (i + 1) * bucket_size]\n",
    "        for i in range(10)\n",
    "    ]\n",
    "\n",
    "    return decile_buckets\n",
    "\n",
    "# Function to convert decile index into folder name\n",
    "def decile_folder(i):\n",
    "    return 't_10' if i == 0 else f't_{i*10}_{(i+1)*10}'\n",
    "\n",
    "\n",
    "\n",
    "# json_content = get_cot_length(\"/Users/kevinxie/Library/CloudStorage/GoogleDrive-kevinxie2024@gmail.com/My Drive/cot-analysis/combined-results/68.NUBES/Mistral-Small-3.1-24B-Instruct-2503/68.NUBES-cot-greedy-42.result.json\")\n",
    "\n",
    "# bucket(json_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ba313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "for task_name in task_folders:\n",
    "\n",
    "    task_path = os.path.join(destination, task_name)\n",
    "    if not os.path.isdir(task_path):\n",
    "        continue\n",
    "\n",
    "    for model_name in os.listdir(task_path):\n",
    "\n",
    "        model_path = os.path.join(task_path, model_name)\n",
    "        if not os.path.isdir(model_path):\n",
    "            continue\n",
    "\n",
    "        # gather *all* the CoT files for this (task, model) pair\n",
    "        cot_files = [f for f in os.listdir(model_path) if \"-cot-\" in f]\n",
    "        if not cot_files:\n",
    "            continue\n",
    "\n",
    "        cot_file = cot_files[0]\n",
    "\n",
    "\n",
    "        cot_file_path = os.path.join(model_path, cot_file)\n",
    "\n",
    "        # Read the contents of the CoT file\n",
    "\n",
    "        aug_data = aug_cot_length(cot_file_path)\n",
    "\n",
    "        decile_buckets = bucket(aug_data)\n",
    "\n",
    "        # Replace this with your actual decile_buckets\n",
    "        # decile_buckets = [...]\n",
    "\n",
    "        for i, bucket in enumerate(decile_buckets):\n",
    "            if not bucket:\n",
    "                continue  # Skip empty buckets\n",
    "\n",
    "            # Create path like cot_length/t_10/task_name/model_name/\n",
    "            decile_path = os.path.join(base_dir, decile_folder(i), task_name, model_name)\n",
    "\n",
    "            # Create directories\n",
    "            os.makedirs(decile_path, exist_ok=True)\n",
    "\n",
    "            # Save JSON file\n",
    "            file_path = os.path.join(decile_path, 'bucket.json')\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(bucket, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "            print(f'Saved decile bucket {i+1} to {file_path}')\n",
    "\n",
    "        break\n",
    "        \n",
    "    break\n",
    "        # For each output, update it to have the cot length attribute\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
